# -*- coding: utf-8 -*-
"""Desharnais_effort_estimation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1P_heUnD1PCQ32IFMeFcEcExitZ4sRIXE

Linear Regression on Desharnais Dataset
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn import linear_model
from sklearn.linear_model import LinearRegression
from sklearn.svm import SVR
from sklearn.ensemble import RandomForestRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.linear_model import Ridge
from sklearn.feature_selection import mutual_info_regression
from sklearn.feature_selection import SelectPercentile
from sklearn.model_selection import GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, root_mean_squared_error

from google.colab import drive
drive.mount('/content/drive')

# Load CSV
df = pd.read_csv("/content/drive/MyDrive/Datasets/desharnais(days).csv")
df = df.drop(columns=['id'])
# Define input features and target
X = df.drop(columns=['Effort', 'EffortInDays']) # All columns except the target
y = df['EffortInDays']

df.isnull().sum()

df.corr()

colormap = plt.cm.viridis
plt.figure(figsize=(15,15))
plt.title('Pearson Correlation of Features', y=1.05, size=15)
sns.set(font_scale=1.05)
sns.heatmap(df.astype(float).corr(),linewidths=0.1,vmax=1.0, square=True,cmap=colormap, linecolor='white', annot=True)

mutual_info = mutual_info_regression(X, y)
mutual_info

mutual_info = pd.Series(mutual_info)
mutual_info.index = X.columns
mutual_info.sort_values(ascending=False)

mutual_info.sort_values(ascending=False).plot.bar(figsize=(15,5))

selected_top_columns = SelectPercentile(mutual_info_regression, percentile=65)
selected_top_columns.fit(X, y)
X.columns[selected_top_columns.get_support()]

"""Full dataset without scaling"""

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""Full dataset with scaling"""

scaler = StandardScaler()
X2_train = scaler.fit_transform(X_train)
X2_test = scaler.transform(X_test)
y2_train = y_train
y2_test = y_test

"""Feature selected dataset without scaling"""

X3 = df[['Length', 'Transactions', 'Entities', 'PointsNonAdjust', 'Adjustment','PointsAjust', 'Language']]
y3 = df['EffortInDays']

X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.2, random_state=42)

"""Feature selected dataset with scaling"""

X4_train = scaler.fit_transform(X3_train)
X4_test = scaler.transform(X3_test)
y4_train = y3_train
y4_test = y3_test

"""**Linear Regression**

Model Training
"""

lr1 = LinearRegression()
lr1.fit(X_train,y_train)

lr3 = LinearRegression()
lr3.fit(X3_train,y3_train)

"""Predictions"""

lr1_pred = lr1.predict(X_test)
lr3_pred = lr3.predict(X3_test)

"""Evaluation"""

rmse_lr1 = root_mean_squared_error(y_test, lr1_pred)
r2_lr1 = r2_score(y_test, lr1_pred)
mae_lr1 = mean_absolute_error(y_test, lr1_pred)

print("\nAll features no scaling:-")
print(f"Root mean Squared Error: {rmse_lr1:.4f}")
print(f"Mean Absolute Eroor: {mae_lr1:.4f}")
print(f"R² Score: {r2_lr1:.4f}")

rmse_lr3 = root_mean_squared_error(y_test, lr3_pred)
r2_lr3 = r2_score(y_test, lr3_pred)
mae_lr3 = mean_absolute_error(y_test, lr3_pred)

print("\nSelected features no scaling:-")
print(f"Root mean Squared Error: {rmse_lr3:.4f}")
print(f"Mean Absolute Eroor: {mae_lr3:.4f}")
print(f"R² Score: {r2_lr3:.4f}")

fig = plt.figure(figsize=(12, 6))
plt.scatter(y_test,lr1_pred,color='coral', linewidths=2, edgecolors='k')
plt.xlabel('Effort')
plt.ylabel('Predictions')
plt.title('Linear Regression Prediction Performance (all features, No scaling)')
plt.grid()

"""**SVM**

Model training
"""

svm1 = SVR(kernel='linear')
svm1.fit(X_train,y_train)

svm3 = SVR(kernel='linear')
svm3.fit(X3_train,y3_train)

"""Predictions"""

svm1_pred = svm1.predict(X_test)
svm3_pred = svm3.predict(X3_test)

"""Evaluations"""

rmse_svm1 = root_mean_squared_error(y_test, svm1_pred)
r2_svm1 = r2_score(y_test, svm1_pred)
mae_svm1 = mean_absolute_error(y_test,svm1_pred)

print("\nAll features no scaling:-")
print(f"Root mean Squared Error: {rmse_svm1:.4f}")
print(f"Mean Absolute Eroor: {mae_svm1:.4f}")
print(f"R² Score: {r2_svm1:.4f}")

rmse_svm3 = root_mean_squared_error(y_test, svm3_pred)
r2_svm3 = r2_score(y_test, svm3_pred)
mae_svm3 = mean_absolute_error(y_test, svm3_pred)

print("\nSelected features no scaling:-")
print(f"Root mean Squared Error: {rmse_svm3:.4f}")
print(f"Mean Absolute Eroor: {mae_svm3:.4f}")
print(f"R² Score: {r2_svm3:.4f}")

fig = plt.figure(figsize=(12, 6))
plt.scatter(y3_test,svm3_pred,color='coral', linewidths=2, edgecolors='k')
plt.xlabel('Effort')
plt.ylabel('Predictions')
plt.title('Unoptimized SVM prediction Performance (selected features, No scaling)')
plt.grid()
plt.show()

"""**Optimising SVM**"""

param_grid = {'C':[1, 10, 100],
             'kernel':['linear'],
             'gamma':('auto', 'scale')}
grid = GridSearchCV(SVR(), param_grid, verbose=3, n_jobs=-1)

grid.fit(X3_train, y3_train)

grid.best_params_

grid.best_estimator_

grid_predictions = grid.predict(X3_test)

rmse_svm3 = root_mean_squared_error(y_test, grid_predictions)
r2_svm3 = r2_score(y_test, grid_predictions)
mae_svm3 = mean_absolute_error(y_test, grid_predictions)

#print("\nSelected features no scaling:-")
print(f"Root mean Squared Error: {rmse_svm3:.4f}")
print(f"Mean Absolute Eroor: {mae_svm3:.4f}")
print(f"R² Score: {r2_svm3:.4f}")

fig = plt.figure(figsize=(12, 6))
plt.scatter(y3_test,grid_predictions,color='coral', linewidths=2, edgecolors='k')
plt.xlabel('Effort')
plt.ylabel('Predictions')
plt.title('Optimized SVM prediction Performance (selected features, No scaling)')
plt.grid()
plt.show()

"""**Random Forest Regression**

Model training
"""

rf1 = RandomForestRegressor()
rf1.fit(X_train, y_train)

rf2 = RandomForestRegressor()
rf2.fit(X2_train, y2_train)

rf3 = RandomForestRegressor()
rf3.fit(X3_train, y3_train)

rf4 = RandomForestRegressor()
rf4.fit(X4_train, y4_train)

"""Predictions"""

rf1_pred = rf1.predict(X_test)
rf2_pred = rf2.predict(X2_test)
rf3_pred = rf3.predict(X3_test)
rf4_pred = rf4.predict(X4_test)

"""Evaluation"""

rmse_rf1 = root_mean_squared_error(y_test, rf1_pred)
r2_rf1 = r2_score(y_test, rf1_pred)
mae_rf1 = mean_absolute_error(y_test,rf1_pred)

print("\nAll features no scaling:-")
print(f"Root mean Squared Error: {rmse_rf1:.4f}")
print(f"Mean Absolute Eroor: {mae_rf1:.4f}")
print(f"R² Score: {r2_rf1:.4f}")

rmse_rf2 = root_mean_squared_error(y2_test, rf2_pred)
r2_rf2 = r2_score(y2_test, rf2_pred)
mae_rf2 = mean_absolute_error(y2_test,rf2_pred)

print("\nAll features with scaling:-")
print(f"Root mean Squared Error: {rmse_rf2:.4f}")
print(f"Mean Absolute Eroor: {mae_rf2:.4f}")
print(f"R² Score: {r2_rf2:.4f}")

rmse_rf3 = root_mean_squared_error(y3_test, rf3_pred)
r2_rf3 = r2_score(y3_test, rf3_pred)
mae_rf3 = mean_absolute_error(y3_test,rf3_pred)

print("\nSelected features no scaling:-")
print(f"Root mean Squared Error: {rmse_rf3:.4f}")
print(f"Mean Absolute Eroor: {mae_rf3:.4f}")
print(f"R² Score: {r2_rf3:.4f}")

rmse_rf4 = root_mean_squared_error(y4_test, rf4_pred)
r2_rf4 = r2_score(y4_test, rf4_pred)
mae_rf4 = mean_absolute_error(y4_test,rf4_pred)

print("\nSelected features with scaling:-")
print(f"Root mean Squared Error: {rmse_rf4:.4f}")
print(f"Mean Absolute Eroor: {mae_rf4:.4f}")
print(f"R² Score: {r2_rf4:.4f}")

fig = plt.figure(figsize=(12, 6))
plt.scatter(y2_test,rf1_pred,color='coral', linewidths=2, edgecolors='k')
plt.xlabel('Effort')
plt.ylabel('Predictions')
plt.title('Random Forest Regressor Prediction Performance (All features, with scaling)')
plt.grid()
plt.show()

"""Optimising RF Regressor"""

rf_param_grid = {
    'criterion': ['squared_error', 'absolute_error'],
    'bootstrap': [False, True],
    'n_estimators': [100, 500, 1000],
    'max_features': ['sqrt', 'log2']
}

rf_grid = GridSearchCV(RandomForestRegressor(), rf_param_grid, verbose=3, n_jobs=-1)

rf_grid.fit(X2_train, y2_train)

rf_grid.best_params_

rf_grid.best_estimator_

rf_grid_predictions = rf_grid.predict(X2_test)

rmse_rf2 = root_mean_squared_error(y2_test, rf_grid_predictions)
r2_rf2 = r2_score(y2_test, rf_grid_predictions)
mae_rf2 = mean_absolute_error(y2_test,rf_grid_predictions)

#print("\nAll features with scaling:-")
print(f"Root mean Squared Error: {rmse_rf2:.4f}")
print(f"Mean Absolute Eroor: {mae_rf2:.4f}")
print(f"R² Score: {r2_rf2:.4f}")

"""**KNN**

Model training
"""

kn2 = KNeighborsRegressor()
kn2.fit(X2_train, y2_train)

kn4 = KNeighborsRegressor()
kn4.fit(X4_train, y4_train)

"""Predictions"""

kn2_pred = kn2.predict(X2_test)
kn4_pred = kn4.predict(X4_test)

"""Evaluations"""

rmse_kn2 = root_mean_squared_error(y2_test, kn2_pred)
r2_kn2 = r2_score(y2_test, kn2_pred)
mae_kn2 = mean_absolute_error(y2_test,kn2_pred)

print("\nAll features with scaling:-")
print(f"Root mean Squared Error: {rmse_kn2:.4f}")
print(f"Mean Absolute Eroor: {mae_kn2:.4f}")
print(f"R² Score: {r2_kn2:.4f}")

rmse_kn4 = root_mean_squared_error(y4_test,kn4_pred)
r2_kn4 = r2_score(y4_test, kn4_pred)
mae_kn4 = mean_absolute_error(y4_test,kn4_pred)

print("\nSelected features with scaling:-")
print(f"Root mean Squared Error: {rmse_kn4:.4f}")
print(f"Mean Absolute Eroor: {mae_kn4:.4f}")
print(f"R² Score: {r2_kn4:.4f}")

fig = plt.figure(figsize=(12, 6))
plt.scatter(y2_test,kn2_pred,color='coral', linewidths=2, edgecolors='k')
plt.xlabel('Effort')
plt.ylabel('Predictions')
plt.title('KNeighbors Regressor Prediction Performance (Selected features, with scaling)')
plt.grid()
plt.show()

"""Lasso Regression

Model Training
"""

lsr1 = linear_model.Lasso(max_iter=1500)
lsr1.fit(X_train, y_train)

lsr3 = linear_model.Lasso(max_iter=1500)
lsr3.fit(X3_train, y3_train)

"""Predictions"""

lsr1_pred = lsr1.predict(X_test)
lsr3_pred = lsr3.predict(X3_test)

"""Evaluation"""

rmse_lsr1 = root_mean_squared_error(y_test, lsr1_pred)
r2_lsr1 = r2_score(y_test, lsr1_pred)
mae_lsr1 = mean_absolute_error(y_test,lsr1_pred)

print("\nAll features with scaling:-")
print(f"Root mean Squared Error: {rmse_lsr1:.4f}")
print(f"Mean Absolute Eroor: {mae_lsr1:.4f}")
print(f"R² Score: {r2_lsr1:.4f}")

rmse_lsr3 = root_mean_squared_error(y3_test,lsr3_pred)
r2_lsr3 = r2_score(y3_test, lsr3_pred)
mae_lsr3 = mean_absolute_error(y3_test,lsr3_pred)

print("\nSelected features with scaling:-")
print(f"Root mean Squared Error: {rmse_lsr3:.4f}")
print(f"Mean Absolute Eroor: {mae_lsr3:.4f}")
print(f"R² Score: {r2_lsr3:.4f}")

fig = plt.figure(figsize=(12, 6))
plt.scatter(y2_test,kn2_pred,color='coral', linewidths=2, edgecolors='k')
plt.xlabel('Effort')
plt.ylabel('Predictions')
plt.title('KNeighbors Regressor Prediction Performance (Selected features, with scaling)')
plt.grid()
plt.show()

"""Ridge Regression

Model Training
"""

rr1 = Ridge()
rr1.fit(X_train, y_train)

rr2 = Ridge()
rr2.fit(X2_train, y2_train)

rr3 = Ridge()
rr3.fit(X3_train, y3_train)

rr4 = Ridge()
rr4.fit(X4_train, y4_train)

"""Predictions"""

rr1_pred = rr1.predict(X_test)
rr2_pred = rr2.predict(X2_test)
rr3_pred = rr3.predict(X3_test)
rr4_pred = rr4.predict(X4_test)

"""Evaluation"""

rmse_rr1 = root_mean_squared_error(y_test, rr1_pred)
r2_rr1 = r2_score(y_test, rr1_pred)
mae_rr1 = mean_absolute_error(y_test,rr1_pred)

print("\nAll features with scaling:-")
print(f"Root mean Squared Error: {rmse_rr1:.4f}")
print(f"Mean Absolute Eroor: {mae_rr1:.4f}")
print(f"R² Score: {r2_rr1:.4f}")

rmse_rr2 = root_mean_squared_error(y2_test,rr2_pred)
r2_rr2 = r2_score(y2_test, rr2_pred)
mae_rr2 = mean_absolute_error(y2_test,rr2_pred)

print("\nSelected features with scaling:-")
print(f"Root mean Squared Error: {rmse_rr2:.4f}")
print(f"Mean Absolute Eroor: {mae_rr2:.4f}")
print(f"R² Score: {r2_rr2:.4f}")

rmse_rr3 = root_mean_squared_error(y3_test, rr3_pred)
r2_rr3 = r2_score(y3_test, rr3_pred)
mae_rr3 = mean_absolute_error(y3_test,rr3_pred)

print("\nAll features with scaling:-")
print(f"Root mean Squared Error: {rmse_rr3:.4f}")
print(f"Mean Absolute Eroor: {mae_rr3:.4f}")
print(f"R² Score: {r2_rr3:.4f}")

rmse_rr4 = root_mean_squared_error(y4_test,rr4_pred)
r2_rr4 = r2_score(y4_test, rr4_pred)
mae_rr4 = mean_absolute_error(y4_test,rr4_pred)

print("\nSelected features with scaling:-")
print(f"Root mean Squared Error: {rmse_rr4:.4f}")
print(f"Mean Absolute Eroor: {mae_rr4:.4f}")
print(f"R² Score: {r2_rr4:.4f}")